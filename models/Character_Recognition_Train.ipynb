{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Character_Recognition_Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iUO7GKN997i"
      },
      "source": [
        "# **Imports and data linking to Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYNgwfSSL0L5"
      },
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpBPHL-nkMfq"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#extract data\n",
        "!unzip \"/content/drive/MyDrive/Data/final_char_data.zip\" -d \"/content/char40_split\"\n",
        "!unzip \"/content/drive/MyDrive/Data/hhd40.zip\" -d \"/content/pretrain_set\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbU5UKCYfiLo"
      },
      "source": [
        "# **Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvgbodAPfhQR"
      },
      "source": [
        "train_path = \"/content/char40_split/final_char_data/train\"\n",
        "test_path =  \"/content/char40_split/final_char_data/val\"\n",
        "test_path_no_morph = \"/content/char40_split/final_char_data/val_no_morph\"\n",
        "pretrain_path = \"/content/pretrain_set/binarized_hhd_40x40\"\n",
        "\n",
        "class ThresholdTransform(object):\n",
        "  def __init__(self, thr_255):\n",
        "    self.thr = thr_255 / 255.  # input threshold for [0..255] gray level, convert to [0..1]\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return (x < self.thr).to(x.dtype)  # do not change the data type\n",
        "\n",
        "class CharDataset(Dataset):\n",
        "    def __init__(self, char_directory, size=(40, 40), normalize=False):\n",
        "        super().__init__()\n",
        "        # this should be the path to the directory where the char folders are\n",
        "        self.char_directory = char_directory\n",
        "        self.char_idx = dict()\n",
        "        self.label_idx = dict()\n",
        "        # go thru the folders and add the labels / path to chars to the dicts\n",
        "        cnt = 0\n",
        "        for j, label in enumerate(os.listdir(self.char_directory)):\n",
        "          label_dir = os.path.join(self.char_directory, label)\n",
        "          for i, fl in enumerate(os.listdir(label_dir)):\n",
        "              self.label_idx[cnt] = label\n",
        "              self.char_idx[cnt] = os.path.join(label_dir, fl)\n",
        "              cnt += 1\n",
        "        self.idx = 1\n",
        "        # create a list of the indexes randomly shuffled use this to accses the dict\n",
        "        # in this way we accses every char in the dict in a random order\n",
        "        list_char = list(self.char_idx.keys())\n",
        "        random.shuffle(list_char)\n",
        "        self.random_keys = list_char\n",
        "        self.range = len(self.char_idx.keys()) \n",
        "        if normalize:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize(size),\n",
        "                transforms.Grayscale(num_output_channels=1),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize(size),\n",
        "                transforms.Grayscale(num_output_channels=1),\n",
        "                transforms.ToTensor(),\n",
        "                ThresholdTransform(thr_255=200)                               \n",
        "            ])\n",
        "        \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #print(self.char_idx[self.random_keys[idx]])\n",
        "        # char_img = cv2.imread(self.char_idx[self.random_keys[idx]])\n",
        "        \n",
        "        # ret, char_img = cv2.threshold(char_img,0,1,cv2.THRESH_BINARY)\n",
        "        # char_img = Image.fromarray(char_img)\n",
        "        char_img = Image.open(self.char_idx[self.random_keys[idx]])\n",
        "        char_label = self.label_idx[self.random_keys[idx]]\n",
        "        char_img = self.transform(char_img)\n",
        "\n",
        "        return char_img, char_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.char_idx.keys())\n",
        "\n",
        "train_data = CharDataset(train_path)\n",
        "train_dl = DataLoader(train_data, batch_size=1)\n",
        "test_data = CharDataset(test_path)\n",
        "test_data_no_morph = CharDataset(test_path_no_morph)\n",
        "test_dl = DataLoader(test_data, batch_size=1)\n",
        "pretrain_data = CharDataset(pretrain_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sdoDvAP1JQL"
      },
      "source": [
        "# Recognizer Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_opePGb-RjXq"
      },
      "source": [
        "class TheRecognizer(nn.Module):\n",
        "  def __init__(self, l2_reg, lr):\n",
        "    super(TheRecognizer, self).__init__()\n",
        "    self.conv_layers = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5,stride=1, padding=0),\n",
        "        nn.BatchNorm2d(10),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Conv2d(10, 15, 5, 1, 0),\n",
        "        nn.BatchNorm2d(15),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "    )\n",
        "    self.lin_layers = nn.Sequential(\n",
        "        nn.Linear(7*7*15, 300),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(300, 27),\n",
        "        nn.LogSoftmax(dim=1)\n",
        "    )\n",
        "\n",
        "    self.opt = torch.optim.Adam(params=self.parameters(), weight_decay=l2_reg, lr=lr)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_layers(x)\n",
        "    x = x.view(-1, 7*7*15)\n",
        "    x = self.lin_layers(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def load_checkpoint(self, ckpt_path, map_location=None):\n",
        "    ckpt = torch.load(ckpt_path, map_location=map_location)\n",
        "    #print(' [*] Loading checkpoint from %s succeed!' % ckpt_path)\n",
        "    return ckpt\n",
        "\n",
        "  def save_checkpoint(self, state, save_path):\n",
        "    torch.save(state, save_path)    \n",
        "\n",
        "  def load_model(self, ckpt):\n",
        "      self.epoch = ckpt['epoch']\n",
        "      self.load_state_dict(ckpt['weights'])\n",
        "      self.opt.load_state_dict(ckpt['optimizer'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNBQrikQ-JLF"
      },
      "source": [
        "# Helper functions to compute accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upYJ89polcQE"
      },
      "source": [
        "name2idx = {'Alef': 0, 'Ayin': 1, 'Bet': 2, 'Dalet': 3, 'Gimel' : 4, 'He': 5,\n",
        "            'Het': 6, 'Kaf': 7, 'Kaf-final': 8, 'Lamed': 9, 'Mem': 10, \n",
        "            'Mem-medial': 11, 'Nun-final': 12, 'Nun-medial': 13, 'Pe': 14,\n",
        "            'Pe-final': 15, 'Qof': 16, 'Resh': 17, 'Samekh': 18, 'Shin': 19,\n",
        "            'Taw': 20, 'Tet': 21, 'Tsadi-final': 22, 'Tsadi-medial': 23,\n",
        "            'Waw': 24, 'Yod': 25, 'Zayin': 26}\n",
        "\n",
        "def get_test_acc(test_dl, model, device, con_mat = False):\n",
        "  correct = 0\n",
        "  wrong = 0\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "  for t, data in enumerate(test_dl):\n",
        "    img, label = data\n",
        "    img = img.to(device)\n",
        "    out = model(img)\n",
        "    label_idx = name2idx[label[0]]\n",
        "    out_idx = torch.argmax(out).detach().cpu().numpy()\n",
        "    if con_mat:\n",
        "      y_true.append(label_idx)\n",
        "      y_pred.append(out_idx)\n",
        "    if out_idx == label_idx:\n",
        "      correct += 1\n",
        "    else:\n",
        "      wrong += 1\n",
        "  if con_mat:\n",
        "    c_mat = confusion_matrix(y_true, y_pred)\n",
        "    sn.heatmap(c_mat)\n",
        "  return correct/(correct+wrong)\n",
        "\n",
        "def get_train_acc(train_dl, model, device):\n",
        "  correct = 0\n",
        "  wrong = 0 \n",
        "  for t, data in enumerate(train_dl):\n",
        "    img, label = data\n",
        "    img = img.to(device)\n",
        "    out = model(img)\n",
        "    label_idx = name2idx[label[0]]\n",
        "    out_idx = torch.argmax(out).detach().cpu().numpy()\n",
        "    if out_idx == label_idx:\n",
        "      correct += 1\n",
        "    else:\n",
        "      wrong += 1\n",
        "    \n",
        "  return correct/(correct+wrong)\n",
        "\n",
        "def get_pretrain_acc(train_dl, model, device):\n",
        "  correct = 0\n",
        "  wrong = 0 \n",
        "  for t, data in enumerate(train_dl):\n",
        "    img, label = data\n",
        "    img = img.to(device)\n",
        "    out = model(img)\n",
        "    out_idx = torch.argmax(out).detach().cpu().numpy()\n",
        "    if int(out_idx) == int(label[0]):\n",
        "      correct += 1\n",
        "    else:\n",
        "      wrong += 1\n",
        "  return correct/(correct+wrong)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY8E4g0_vR0k"
      },
      "source": [
        "# Pretraining Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KSmyPvYvU--"
      },
      "source": [
        "#Hyperparamters\n",
        "lr = 0.001\n",
        "batch_size = 15\n",
        "epochs = 5\n",
        "l2_reg = 0.0001\n",
        "\n",
        "device = 'cuda'\n",
        "model = TheRecognizer(l2_reg, lr)\n",
        "model.to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "opt = model.opt\n",
        "pretrain_dl = DataLoader(pretrain_data, batch_size = batch_size)\n",
        "pretrain_dl_test = DataLoader(pretrain_data, batch_size = 1)\n",
        "test_dl = DataLoader(test_data, batch_size=1)\n",
        "\n",
        "\n",
        "for i in range(epochs):\n",
        "  for j, data in enumerate(pretrain_dl):\n",
        "    opt.zero_grad()\n",
        "    img, label = data\n",
        "    label = np.asarray(label, dtype=int)\n",
        "    img = img.to(device)\n",
        "    out = model(img)\n",
        "    target = torch.LongTensor(label).to(device)\n",
        "    loss = criterion(out, target)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "  print(\"train acc this epoch\", get_pretrain_acc(pretrain_dl_test, model, device))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRuM0TMyxGN-"
      },
      "source": [
        "# save the pretrained model\n",
        "save_dict = {\n",
        "        'epoch': 0,\n",
        "        'weights': model.state_dict(),\n",
        "        'optimizer': opt.state_dict()\n",
        "    }\n",
        "\n",
        "model.save_checkpoint(save_dict, save_path='pretrained_net.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6AppoOwBOXs"
      },
      "source": [
        "# Cross-validation on Pretrained model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dxUEIAFyDEi"
      },
      "source": [
        "def test_fold(test_list, model, device):\n",
        "  correct = 0\n",
        "  wrong = 0\n",
        "  for img, label in test_list:\n",
        "    img = img.to(device)\n",
        "    out = model(img)\n",
        "    label_idx = name2idx[label[0]]\n",
        "    out_idx = torch.argmax(out).detach().cpu().numpy()\n",
        "    if out_idx == label_idx:\n",
        "      correct += 1\n",
        "    else:\n",
        "      wrong += 1\n",
        "  return (correct/(correct+wrong))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQE_2n0oBNnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ec47e5-d84b-42d5-dffe-a0ac4b33c588"
      },
      "source": [
        "# fixed Hyperparamters\n",
        "l2_reg = 0\n",
        "lr = 0.00155\n",
        "epochs = 10\n",
        "batch_size = 1\n",
        "device = 'cuda'\n",
        "criterion = nn.NLLLoss()\n",
        "k = 5\n",
        "lr_list = []\n",
        "train_dl = DataLoader(train_data, batch_size = batch_size)\n",
        "fold_length = len(train_dl) / k\n",
        "\n",
        "# cross-val loop\n",
        "for lr in np.arange(0.0001, 0.005, 0.0005):\n",
        "  total_acc = 0\n",
        "  fold_length_start = 0\n",
        "  fold_length_end = fold_length\n",
        "  for fold in range(k):\n",
        "    model = TheRecognizer(l2_reg, lr)\n",
        "    # load the pretrained model each time to reset the parameters\n",
        "    model.load_model(model.load_checkpoint('pretrained_net.ckpt', map_location=torch.device('cuda')))\n",
        "    model.to(device)\n",
        "    opt = torch.optim.Adam(params=model.parameters(), weight_decay=l2_reg, lr=lr)\n",
        "    # cross-val data split\n",
        "    test_list = []\n",
        "    train_list = []\n",
        "    for j, data in enumerate(train_dl):\n",
        "        if j < fold_length_end and j > fold_length_start:\n",
        "          test_list.append(data)\n",
        "        else:\n",
        "          train_list.append(data)\n",
        "    fold_length_start += fold_length\n",
        "    fold_length_end += fold_length\n",
        "    # train on part of the data\n",
        "    for u in range(epochs):  \n",
        "      for img, label in train_list:\n",
        "        # emtpy label list each iteration\n",
        "        label_idx = []\n",
        "        opt.zero_grad()\n",
        "        img = img.to(device)\n",
        "        out = model(img)\n",
        "        # loop and make list of label idx\n",
        "        for x in range(len(label)):\n",
        "          label_idx.append(name2idx[label[x]])\n",
        "        target = torch.LongTensor(label_idx).to(device)\n",
        "        loss = criterion(out, target)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    # evaluate on other part\n",
        "    total_acc += test_fold(test_list, model, device)\n",
        "\n",
        "  print(\"current lr rate: \", lr)\n",
        "  print(\"Acc: \", total_acc / k)\n",
        "  lr_list.append({lr, (total_acc/k)})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current lr rate:  0\n",
            "Acc:  0.9575327130276895\n",
            "current lr rate:  0\n",
            "Acc:  0.953432871778635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCOMa3QxdUAF"
      },
      "source": [
        "# Training loop on whole train data and testing accuracy on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euXr3wdWdTmy"
      },
      "source": [
        "# Best Hyperparamters found using cross-validation\n",
        "lr = 0.00155\n",
        "batch_size = 1\n",
        "epochs = 20\n",
        "l2_reg = 0.0001\n",
        "model = TheRecognizer(l2_reg, lr)\n",
        "# load the pretrained model each time to reset the parameters\n",
        "model.load_model(model.load_checkpoint('pretrained_net.ckpt', map_location=torch.device('cuda')))\n",
        "model.to(device)\n",
        "# device = 'cuda'\n",
        "# model = TheRecognizer()\n",
        "# model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), weight_decay=l2_reg)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "train_dl = DataLoader(train_data, batch_size = batch_size)\n",
        "test_dl = DataLoader(test_data, batch_size=1)\n",
        "test_dl_no_morph = DataLoader(test_data_no_morph, batch_size=1)\n",
        "best_acc = 0\n",
        "\n",
        "for i in range(epochs):\n",
        "  for j, data in enumerate(train_dl):\n",
        "    # emtpy label list each iteration\n",
        "    label_idx = []\n",
        "    optimizer.zero_grad()\n",
        "    img, label = data\n",
        "    img = img.to(device)\n",
        "    out = model(img)\n",
        "    # loop and make list of label idx\n",
        "    for x in range(len(label)):\n",
        "      label_idx.append(name2idx[label[x]])\n",
        "    target = torch.LongTensor(label_idx).to(device)\n",
        "    loss = criterion(out, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(i)\n",
        "  test_acc = get_test_acc(test_dl, model, device)\n",
        "  print(\"Train acc this epoch\", get_train_acc(train_dl, model, device))\n",
        "  print(\"Test acc this epoch\", test_acc)\n",
        "  if test_acc > best_acc:\n",
        "    best_acc = test_acc\n",
        "    save_dict = {\n",
        "        'epoch': 0,\n",
        "        'weights': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()\n",
        "    }\n",
        "\n",
        "    model.save_checkpoint(save_dict, save_path='40_char_rec.ckpt')\n",
        "    print(\"BEST ACCURACY: \", best_acc)\n",
        "  print(\"Test acc this epoch no morph\", get_test_acc(test_dl_no_morph, model, device))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD-CzcMvsDX1"
      },
      "source": [
        "# save the final recognizer model \n",
        "save_dict = {\n",
        "        'epoch': 0,\n",
        "        'weights': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()\n",
        "    }\n",
        "\n",
        "model.save_checkpoint(save_dict, save_path='40_char_rec.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}